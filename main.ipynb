{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Like Prediction @310ai Competition\n",
    "\n",
    "This notebook is for the competition posted by the @310ai on 15th of April. I will approach the competition as a project following the CRISP-DM methodology and try to explain the approach in every steps of the way.\n",
    "\n",
    "The main and short summary of this competition is **\"given an Instagram post predict the number of likes\"**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "First thing first, there are some important points that we have to consider which are forced by the Instagram. This points will result in some features that are effective in percision of the model. In the following section we will discuss them further.\n",
    "\n",
    "***Are we try to predict the number of likes for an Instagram post of our own or not?***\n",
    "\n",
    "This question might seem a little odd, but let me explain it. Each Instagram post consists of some metrics that show the performance of the post among the users. We will call these **\"Performance Metrics\"**. Some of these performance metrics such as amount of like, amount of columns, caption and etc, are publicly availble, in other words, any user on the Instagram can see them.\n",
    "\n",
    "But some of the performance metrics, are not publicly available, in order to see them, we need to authenticate as the owner of the page (will discuss about this part further in this section.), some of these private performance metrics are, amount of share, amount of save, amount of reach, amount of profile visits, amount of follows, amount of impression and etc.\n",
    "\n",
    "Obviously, if we try to predict the amount of like for a page that we don't own, we can not access these features, we will go for a page that we don't have access to it for this competition.\n",
    "\n",
    "In the further section I will try to address the questions of the competitions in combination of code and text. Please have in mind to follow the chosen methodology I might change the order of questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Requirements and Data Collection\n",
    "\n",
    "In this section I will tackle the questions mainly related to these parts of the challenge. As we discussed above some useful features introduced that might have effect on the precision of the prediction. But there are some other features, further I will point to some features that are related to the page of the published post.\n",
    "\n",
    "### What Features you used?\n",
    "\n",
    "Each and every page on the Instagram has some features that will distinguish it from other pages, some of these features are like the features discussed above, performance metrics, and some of them are identifiers. Some of the identifiers features are:\n",
    "- `id`: a unique id that is allocated by the Instagram.\n",
    "- `username`: a unique username that each user when created the page chose.\n",
    "\n",
    "Also there are some other features that we will investigate, these features are:\n",
    "- `category_name`: each page based on the published content and some other traits, are categorized into different categories, for instance, Blogger, Personal Blog, Design & Fashion, chef and etc.\n",
    "- `follower`: amount of followers the page has.\n",
    "- `following`: amount of pages that the target page is following.\n",
    "- `ar_effect`: whether the page has published ar effects in the Instagram or not.\n",
    "- `type_business`: whether the page identified itself as business account or not.\n",
    "- `type_professional`: whether the page identified itself as professional account or not.\n",
    "- `verified`: whether the page is verified or not.\n",
    "- `igtv_count`: amount of igtvs posted by the page. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `media_count`: amount of posts, posted by the page.\n",
    "\n",
    "There are some features that are collected organically but can be calculated in the process of feature engineering. Some of them are:\n",
    "- `igtv_avg_view`: The average view of igtvs posted by the page. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `igtv_avg_comment`: The average of comments igtvs acquired. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `igtv_avg_like`: The average of likes igtvs got. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `igtv_avg_duration`: The average of igtv's duration posted by the page. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `igtv_frequency`: How often the page have posted the igtvs. <u>***doublecheck might the name have been changed!***</u>\n",
    "- `media_avg_view`: The average view of media posted by the page.\n",
    "- `media_avg_comment`: The average of comments media acquired.\n",
    "- `media_avg_like`: The average of likes media got.\n",
    "- `media_avg_duration`: The average of media's duration posted by the page.\n",
    "- `media_frequency`: How often the page have posted the media.\n",
    "\n",
    "Last but not least, is the content of the image itself. There are multiple ways to have the content of the image as feature. For instance we can have a classifier network to detect what objects are present in the image and pass them to the like predictor model. Other heuristic approaches might result in a good model, such as passing the image vector generated by the last hidden layer of a classification network as a standalone feature.\n",
    "\n",
    "As you are aware, choosing the best strategy requires some tests, such as A/B tests and trial and error ones, for now I will chose the strategy which will be discussed further that is fastest and heuristic.\n",
    "\n",
    "It's been some time that the Meta, is using an object detection model for generating the Alt Text attribute for the posts. Due to the resources the Meta have in its disposal, this model is extremly face and reliable since it is ran on the server side. Thus for this approach we will use the result of the what objects are present in the image as feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we collect the data?\n",
    "\n",
    "As we discussed above, there are different kind of features, and each group can be collected via different methods.\n",
    "\n",
    "The Instagram provides an API for developers, but due some restrictions and limitations, this API can not provide us the data that we seek. Based on this facts, we will use a heuristic way to collect the data. There will be 2 approaches regarding the matter. one approach which is not very tech-friendly (:D) is to create a scrapper with Selenium page in python to scrap the information we need. Selenium is a website testing library in python that can also be utilized into a webscrapper. This approach has another limitation excluse for users like me, since I'm in Iran right now, access to the Instagram is restricted and we have to use VPNs and geo-restriction bypasses, these tools add another layer of challenge and additional bottleneck. Another approach that I try to utilize, is to use the graphql endpoints to recieve the information needed in JSON format. Eventhough still use of VPNs and similar tools is needed in this approach, but unlike the Selenium this approach doesn't require to load the GUI of Instagram, its much more faster and eligble in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new address for account info.\n",
    "# https://www.instagram.com/nike/?__a=1&__d=dis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
