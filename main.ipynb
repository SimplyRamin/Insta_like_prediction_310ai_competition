{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`To Do:`\n",
    "- [ ] check if post type can be added as feature\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instagram Like Prediction @310ai Competition\n",
    "\n",
    "This notebook is for the competition posted by the @310ai on 15th of April. I will approach the competition as a project following the CRISP-DM methodology and try to explain the approach in every steps of the way.\n",
    "\n",
    "The main and short summary of this competition is **\"given an Instagram post predict the number of likes\"**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "First thing first, there are some important points that we have to consider which are forced by the Instagram. This points will result in some features that are effective in percision of the model. In the following section we will discuss them further.\n",
    "\n",
    "***Are we try to predict the number of likes for an Instagram post of our own or not?***\n",
    "\n",
    "This question might seem a little odd, but let me explain it. Each Instagram post consists of some metrics that show the performance of the post among the users. We will call these **\"Performance Metrics\"**. Some of these performance metrics such as amount of like, amount of columns, caption and etc, are publicly availble, in other words, any user on the Instagram can see them.\n",
    "\n",
    "But some of the performance metrics, are not publicly available, in order to see them, we need to authenticate as the owner of the page (will discuss about this part further in this section.), some of these private performance metrics are, amount of share, amount of save, amount of reach, amount of profile visits, amount of follows, amount of impression and etc.\n",
    "\n",
    "Obviously, if we try to predict the amount of like for a page that we don't own, we can not access these features, we will go for a page that we don't have access to it for this competition.\n",
    "\n",
    "Another to have in mind is that, since the post we are going to predict the amount of like for it, is not actually existing, the amount of performance metrics can't be predicted preciesly. In other words, how we can estimate the amount of comments a hypothetical post might recieve if we don't post it actually. Due to this abstraction, the performance metrics for each post is not a good feature for this deed.\n",
    "\n",
    "In the further section I will try to address the questions of the competitions in combination of code and text. Please have in mind to follow the chosen methodology I might change the order of questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Requirements and Data Collection\n",
    "\n",
    "In this section I will tackle the questions mainly related to these parts of the challenge. As we discussed above some useful features introduced that might have effect on the precision of the prediction. But there are some other features, further I will point to some features that are related to the page of the published post.\n",
    "\n",
    "### What Features you used?\n",
    "\n",
    "Each and every page on the Instagram has some features that will distinguish it from other pages, some of these features are like the features discussed above, performance metrics, and some of them are identifiers. Some of the identifiers features are:\n",
    "- `id`: a unique id that is allocated by the Instagram.\n",
    "- `username`: a unique username that each user when created the page chose.\n",
    "\n",
    "Also there are some other features that we will investigate, these features are:\n",
    "- `category_name`: each page based on the published content and some other traits, are categorized into different categories, for instance, Blogger, Personal Blog, Design & Fashion, chef and etc.\n",
    "- `follower`: amount of followers the page has.\n",
    "- `following`: amount of pages that the target page is following.\n",
    "- `ar_effect`: whether the page has published ar effects in the Instagram or not.\n",
    "- `type_business`: whether the page identified itself as business account or not.\n",
    "- `type_professional`: whether the page identified itself as professional account or not.\n",
    "- `verified`: whether the page is verified or not.\n",
    "- `reel_count`: amount of igtvs posted by the page.\n",
    "- `media_count`: amount of posts, posted by the page.\n",
    "\n",
    "There are some features that are collected organically but can be calculated in the process of feature engineering. Some of them are:\n",
    "- `reel_view`: The average view of igtvs posted by the page.\n",
    "- `reel_comment`: The average of comments igtvs acquired.\n",
    "- `reel_like`: The average of likes igtvs got.\n",
    "- `reel_duration`: The average of igtv's duration posted by the page.\n",
    "- `reel_frequency`: How often the page have posted the reels.\n",
    "- `media_avg_view`: The average view of media posted by the page.\n",
    "- `media_avg_comment`: The average of comments media acquired.\n",
    "- `media_avg_like`: The average of likes media got.\n",
    "- `media_avg_duration`: The average of media's duration posted by the page.\n",
    "- `media_frequency`: How often the page have posted the media.\n",
    "\n",
    "Last but not least, is the content of the image itself. There are multiple ways to have the content of the image as feature. For instance we can have a classifier network to detect what objects are present in the image and pass them to the like predictor model. Other heuristic approaches might result in a good model, such as passing the image vector generated by the last hidden layer of a classification network as a standalone feature.\n",
    "\n",
    "As you are aware, choosing the best strategy requires some tests, such as A/B tests and trial and error ones, for now I will chose the strategy which will be discussed further that is fastest and heuristic.\n",
    "\n",
    "It's been some time that the Meta, is using an object detection model for generating the Alt Text attribute for the posts. Due to the resources the Meta have in its disposal, this model is extremly face and reliable since it is ran on the server side. Thus for this approach we will use the result of the what objects are present in the image as feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we collect the data?\n",
    "\n",
    "As we discussed above, there are different kind of features, and each group can be collected via different methods.\n",
    "\n",
    "The Instagram provides an API for developers, but due some restrictions and limitations, this API can not provide us the data that we seek. Based on this facts, we will use a heuristic way to collect the data. There will be 2 approaches regarding the matter. one approach which is not very tech-friendly (:D) is to create a scrapper with Selenium page in python to scrap the information we need. Selenium is a website testing library in python that can also be utilized into a webscrapper. This approach has another limitation excluse for users like me, since I'm in Iran right now, access to the Instagram is restricted and we have to use VPNs and geo-restriction bypasses, these tools add another layer of challenge and additional bottleneck. Another approach that I try to utilize, is to use the graphql endpoints to recieve the information needed in JSON format. Eventhough still use of VPNs and similar tools is needed in this approach, but unlike the Selenium this approach doesn't require to load the GUI of Instagram, its much more faster and eligble in a pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- end point for user information:\n",
    "`https://www.instagram.com/{username}/?__a=1&__d=dis\n",
    "`\n",
    "\n",
    "- end point for post information:\n",
    "`https://www.instagram.com/p/{post_ID}/?__a=1&__d=dis\n",
    "`\n",
    "\n",
    "getting training data for the model:\n",
    "- each json response of an account gives 12 latest post\n",
    "information:\n",
    "\n",
    "  - Alt text information is here: `data['graphql']['user']['edge_owner_to_timeline_media']['edges'][0]['node']['accessibility_caption']`\n",
    "    - each node has type, `GraphImage` is posts which have alt text.\n",
    "    - `GraphVideo` doesn't have alt text.\n",
    "    - `GraphSideCar` is carousel and have alt text.\n",
    "  - number of comments is here: `data['graphql']['user']['edge_owner_to_timeline_media']['edges'][0]['node']['edge_media_to_comment']['count']`\n",
    "  - number of likes is here: `data['graphql']['user']['edge_owner_to_timeline_media']['edges'][0]['node']['edge_liked_by']['count']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# reading accounts lists for gathering training data.\n",
    "with open('Data/top_100_follower.txt') as f:\n",
    "    lines = f.readlines()\n",
    "top_100_followers = lines[0].split(',')\n",
    "\n",
    "with open('Data/top_100_posts.txt') as f:\n",
    "    lines = f.readlines()\n",
    "top_100_posts = lines[0].split(',')\n",
    "\n",
    "# since added try exception in the main body of collecting data, this section is probably unnecessary, double check it.\n",
    "main_accounts_df = pd.DataFrame(columns=['id', 'username', 'category_name', 'follower', 'following', 'ar_effect', 'type_business', 'type_professional', 'verified', 'reel_count', 'reel_avg_view', 'reel_avg_comment', 'reel_avg_like', 'reel_avg_duration', 'reel_frequency', 'media_count', 'media_avg_comment', 'media_avg_like', 'media_frequency'])\n",
    "main_posts_df = pd.DataFrame(columns=['shortcode', 'post_type', 'username', 'like', 'comment', 'object_1', 'object_2', 'object_3', 'object_4', 'object_5','object_6'])\n",
    "\n",
    "def flatten(lst):\n",
    "    \"\"\"A helper function to flatten any dimensional python list to 1D one.\n",
    "\n",
    "    Args:\n",
    "        lst (list): multi dimension python list\n",
    "\n",
    "    Returns:\n",
    "        list: flattened list\n",
    "    \"\"\"\n",
    "    rt = []\n",
    "    for i in lst:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging into the Instagram account\n",
    "This step is necesary for getting information of the images, since majority of information in Instagram are locked behind the authentication wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "login successful\n",
      "csrf_token:  HDaodXrMyStbMY87xZ5vMW5bE5ladNdl\n",
      "session_id:  1691538713%3AkAlqueeCHIFh7V%3A25%3AAYcm5QFb7UuZfvtNxXKZtH9Sy0WXrDIr92QFJ-VlUQ\n"
     ]
    }
   ],
   "source": [
    "link = 'https://www.instagram.com/accounts/login/'\n",
    "login_url = 'https://www.instagram.com/accounts/login/ajax/'\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36',\n",
    "            'referer':'https://www.instagram.com/',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'TE': 'trailers'\n",
    "}\n",
    "\n",
    "\n",
    "current_time = int(datetime.now().timestamp())\n",
    "response = requests.Session().get(link, headers=headers)\n",
    "if response.ok:\n",
    "    csrf = re.findall(r'csrf_token\\\\\":\\\\\"(.*?)\\\\\"',response.text)[0]\n",
    "    username = 'rfdeveloping'\n",
    "    password = 'ramin1234'\n",
    "\n",
    "    payload = {\n",
    "        'username': username,\n",
    "        'enc_password': f'#PWD_INSTAGRAM_BROWSER:0:{current_time}:{password}',\n",
    "        'queryParams': {},\n",
    "        'optIntoOneTap': 'false',\n",
    "        'stopDeletionNonce': '',\n",
    "        'trustedDeviceRecords': '{}'\n",
    "    }\n",
    "\n",
    "    login_header = {\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36',\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"Referer\": \"https://www.instagram.com/accounts/login/\",\n",
    "        \"X-CSRFToken\": csrf,\n",
    "        'Accept': '*/*',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'X-Instagram-AJAX': 'c6412f1b1b7b',\n",
    "        'X-IG-App-ID': '936619743392459',\n",
    "        'X-ASBD-ID': '198387',\n",
    "        'X-IG-WWW-Claim': '0',\n",
    "        'X-Requested-With': 'XMLHttpRequest',\n",
    "        'Origin': 'https://www.instagram.com',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Referer': 'https://www.instagram.com/accounts/login/?',\n",
    "        'Sec-Fetch-Dest': 'empty',\n",
    "        'Sec-Fetch-Mode': 'cors',\n",
    "        'Sec-Fetch-Site': 'same-origin',\n",
    "    }\n",
    "\n",
    "    login_response = requests.post(login_url, data=payload, headers=login_header)\n",
    "    json_data = json.loads(login_response.text)\n",
    "\n",
    "\n",
    "    if json_data['status'] == 'fail':\n",
    "        print(json_data['message'])\n",
    "\n",
    "    elif json_data[\"authenticated\"]:\n",
    "        print(\"login successful\")\n",
    "        cookies = login_response.cookies\n",
    "        cookie_jar = cookies.get_dict()\n",
    "        csrf_token = cookie_jar['csrftoken']\n",
    "        print(\"csrf_token: \", csrf_token)\n",
    "        session_id = cookie_jar['sessionid']\n",
    "        print(\"session_id: \", session_id)\n",
    "\n",
    "    else:\n",
    "        print(\"login failed \", login_response.text)\n",
    "else:\n",
    "    print('error')\n",
    "    print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: instagram\n",
      "Adding instagram information...\n",
      "Getting Posts Information: instagram\n",
      "Adding instagram posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:09<16:19,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: cristiano\n",
      "Adding cristiano information...\n",
      "Getting Posts Information: cristiano\n",
      "Adding cristiano posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  2%|▏         | 2/100 [00:17<14:24,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: leomessi\n",
      "Adding leomessi information...\n",
      "Getting Posts Information: leomessi\n",
      "Adding leomessi posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  3%|▎         | 3/100 [00:30<17:15, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: selenagomez\n",
      "Adding selenagomez information...\n",
      "Getting Posts Information: selenagomez\n",
      "Adding selenagomez posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  4%|▍         | 4/100 [00:40<16:12, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: kyliejenner\n",
      "Adding kyliejenner information...\n",
      "Getting Posts Information: kyliejenner\n",
      "Adding kyliejenner posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  5%|▌         | 5/100 [00:49<15:37,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: therock\n",
      "Adding therock information...\n",
      "Getting Posts Information: therock\n",
      "Adding therock posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  6%|▌         | 6/100 [01:01<16:46, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: arianagrande\n",
      "Adding arianagrande information...\n",
      "Getting Posts Information: arianagrande\n",
      "Adding arianagrande posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  7%|▋         | 7/100 [01:11<15:58, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: kimkardashian\n",
      "Adding kimkardashian information...\n",
      "Getting Posts Information: kimkardashian\n",
      "Adding kimkardashian posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  8%|▊         | 8/100 [01:21<15:55, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Account Information: beyonce\n",
      "Adding beyonce information...\n",
      "Getting Posts Information: beyonce\n",
      "Adding beyonce posts information...\n",
      "Waiting 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramin\\AppData\\Local\\Temp\\ipykernel_14704\\2834331679.py:129: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
      "  8%|▊         | 8/100 [01:31<17:36, 11.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 199\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m# waiting 5 sec for each  user, instagram rate limit\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mWaiting 5 seconds...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# add read main accounts and main posts csv files here as dataframe\n",
    "try:\n",
    "    main_accounts_df = pd.read_csv('Data/accounts.csv')\n",
    "    main_posts_df = pd.read_csv('Data/posts.csv')\n",
    "except:\n",
    "    main_accounts_df = pd.DataFrame(columns=['id', 'username', 'category_name', 'follower', 'following', 'ar_effect', 'type_business', 'type_professional', 'verified', 'reel_count', 'reel_avg_view', 'reel_avg_comment', 'reel_avg_like', 'reel_avg_duration', 'reel_frequency', 'media_count', 'media_avg_comment', 'media_avg_like', 'media_frequency'])\n",
    "    main_posts_df = pd.DataFrame(columns=['shortcode', 'post_type', 'username', 'like', 'comment', 'object_1', 'object_2', 'object_3', 'object_4', 'object_5','object_6'])\n",
    "\n",
    "\n",
    "for username in tqdm(top_100_followers):\n",
    "    print(f'Getting Account Information: {username}')\n",
    "    # loading account information\n",
    "    session = {\n",
    "            \"csrf_token\": csrf_token,\n",
    "            \"session_id\": session_id\n",
    "        }\n",
    "\n",
    "    headers = {\n",
    "            \"x-csrftoken\": session['csrf_token'],\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36',\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"Referer\": \"https://www.instagram.com/accounts/login/\",\n",
    "            'Accept': '*/*',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'X-Instagram-AJAX': 'c6412f1b1b7b',\n",
    "            'X-IG-App-ID': '936619743392459',\n",
    "            'X-ASBD-ID': '198387',\n",
    "            'X-IG-WWW-Claim': '0',\n",
    "            'X-Requested-With': 'XMLHttpRequest',\n",
    "            'Origin': 'https://www.instagram.com',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://www.instagram.com/accounts/login/?',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Site': 'same-origin',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'TE': 'trailers'\n",
    "        }\n",
    "\n",
    "    cookies = {\n",
    "            \"sessionid\": session['session_id'],\n",
    "            \"csrftoken\": session['csrf_token']\n",
    "        }\n",
    "    url = f'https://www.instagram.com/{username}/?__a=1&__d=dis'\n",
    "    res = requests.get(url, headers=headers, cookies=cookies)\n",
    "    # add error handling here based on response codes, reference -> InstagramBot.py\n",
    "\n",
    "    data = res.json()\n",
    "    followers = data['graphql']['user']['edge_followed_by']['count']\n",
    "    following = data['graphql']['user']['edge_follow']['count']\n",
    "    ar_effect = data['graphql']['user']['has_ar_effects']\n",
    "    id = data['graphql']['user']['id']\n",
    "    type_business = data['graphql']['user']['is_business_account']\n",
    "    type_professional = data['graphql']['user']['is_professional_account']\n",
    "    category = data['graphql']['user']['category_name']\n",
    "    verified = data['graphql']['user']['is_verified']\n",
    "    reel_count = data['graphql']['user']['edge_felix_video_timeline']['count']\n",
    "    media_count = data['graphql']['user']['edge_owner_to_timeline_media']['count']\n",
    "    username = data['graphql']['user']['username']\n",
    "\n",
    "    reel_view_list = []\n",
    "    reel_like_list = []\n",
    "    reel_comment_list = []\n",
    "    reel_duration_list = []\n",
    "    reel_timestamp_list = []\n",
    "\n",
    "    media_like_list = []\n",
    "    media_comment_list = []\n",
    "    media_timestamp_list = []\n",
    "\n",
    "    for video in data['graphql']['user']['edge_felix_video_timeline']['edges']:\n",
    "        reel_view_list.append(video['node']['video_view_count'])\n",
    "        reel_comment_list.append(video['node']['edge_media_to_comment']['count'])\n",
    "        reel_timestamp_list.append(video['node']['taken_at_timestamp'])\n",
    "        reel_like_list.append(video['node']['edge_liked_by']['count'])\n",
    "        reel_duration_list.append(video['node']['video_duration'])\n",
    "\n",
    "    for medium in data['graphql']['user']['edge_owner_to_timeline_media']['edges']:\n",
    "        media_like_list.append(medium['node']['edge_liked_by']['count'])\n",
    "        media_comment_list.append(medium['node']['edge_media_to_comment']['count'])\n",
    "        media_timestamp_list.append(medium['node']['taken_at_timestamp'])\n",
    "\n",
    "    \n",
    "    reel_utc_list = [datetime.utcfromtimestamp(ts) for ts in reel_timestamp_list]\n",
    "    media_utc_list = [datetime.utcfromtimestamp(ts) for ts in media_timestamp_list]\n",
    "\n",
    "    reel_utc_difference_list = [reel_utc_list[i] - reel_utc_list[i+1] for i in range(len(reel_utc_list) - 1)]\n",
    "    media_utc_difference_list = [media_utc_list[i] - media_utc_list[i+1] for i in range(len(media_utc_list) - 1)]\n",
    "\n",
    "    if reel_count > 1:\n",
    "        reel_frequency = np.mean(reel_utc_difference_list).days + (np.mean(reel_utc_difference_list).seconds / 86_400) + (np.mean(reel_utc_difference_list).microseconds / 1_000_000 / 84_600)\n",
    "    else:\n",
    "        reel_frequency = 0\n",
    "    media_frequency = np.mean(media_utc_difference_list).days + (np.mean(media_utc_difference_list).seconds / 86_400) + (np.mean(media_utc_difference_list).microseconds / 1_000_000 / 84_600)\n",
    "\n",
    "    reel_view_mean = np.mean(reel_view_list)\n",
    "    reel_like_mean = np.mean(reel_like_list)\n",
    "    reel_comment_mean = np.mean(reel_comment_list)\n",
    "    reel_duration_mean = np.mean(reel_duration_list)\n",
    "\n",
    "    media_like_mean = np.mean(media_like_list)\n",
    "    media_comment_mean = np.mean(media_comment_list)\n",
    "\n",
    "    entry_lst = [id, username, category, followers, following, ar_effect, type_business, type_professional, verified, reel_count, reel_view_mean, reel_comment_mean, reel_like_mean, reel_duration_mean, reel_frequency, media_count, media_comment_mean, media_like_mean, media_frequency]\n",
    "\n",
    "    account_df = pd.DataFrame() #reset variable\n",
    "    account_df = pd.DataFrame([entry_lst], columns=['id', 'username', 'category_name', 'follower', 'following', 'ar_effect', 'type_business', 'type_professional', 'verified', 'reel_count', 'reel_avg_view', 'reel_avg_comment', 'reel_avg_like', 'reel_avg_duration', 'reel_frequency', 'media_count', 'media_avg_comment', 'media_avg_like', 'media_frequency'])\n",
    "\n",
    "    if account_df.username.isin(main_accounts_df.username).bool():\n",
    "        print('User information already exist, skipping...')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Adding {username} information...')\n",
    "        account_df = account_df.astype({\n",
    "            'ar_effect': bool,\n",
    "            'type_business': bool,\n",
    "            'type_professional': bool,\n",
    "            'verified': bool,\n",
    "        })\n",
    "        main_accounts_df = pd.concat([main_accounts_df, account_df], axis=0, join='outer')\n",
    "    \n",
    "    # adding user's posts information\n",
    "    print(f'Getting Posts Information: {username}')\n",
    "    # main lists structure is:\n",
    "    # shortcode, post_type, username, objects\n",
    "    posts_lst = []\n",
    "    for post in data['graphql']['user']['edge_owner_to_timeline_media']['edges']:\n",
    "        temp_lst = []\n",
    "        objects = []\n",
    "        temp_lst.append(post['node']['shortcode'])\n",
    "        temp_lst.append(post['node']['__typename'])\n",
    "        temp_lst.append(data['graphql']['user']['username'])\n",
    "        temp_lst.append(post['node']['edge_liked_by']['count'])\n",
    "        temp_lst.append(post['node']['edge_media_to_comment']['count'])\n",
    "        if post['node']['__typename'] == 'GraphImage' or post['node']['__typename'] == 'GraphSidecar':\n",
    "            if post['node']['accessibility_caption'] == None:\n",
    "                objects = []\n",
    "                continue\n",
    "            # split object-detection output\n",
    "            objects = post['node']['accessibility_caption'].split('.')[1]\n",
    "            # terminating empty lists\n",
    "            if objects:\n",
    "                try:\n",
    "                    # cutting objects\n",
    "                    objects = objects.split('of')[1]\n",
    "                    objects = objects.split('and', 1)\n",
    "                    objects[0] = objects[0].split(',')\n",
    "                    if 'text' in objects[1]:\n",
    "                        objects[1] = 'text'\n",
    "                except:\n",
    "                    continue\n",
    "                # flattening the objects list to make the dimension 1D\n",
    "                objects = flatten(objects)\n",
    "                # terminating leading and trailing spaces from list items\n",
    "                objects = [item.strip() for item in objects]\n",
    "            else:\n",
    "                objects = []\n",
    "        # padding the objects list, we set the limit to 6 objects\n",
    "        objects += ['No Object'] * (6 - len(objects))\n",
    "        if len(objects) > 6:\n",
    "            objects = objects[:6]\n",
    "        temp_lst.append(objects)\n",
    "        posts_lst.append(flatten(temp_lst))\n",
    "\n",
    "    # creating temporary dataframe for posts of this account\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df = pd.DataFrame(posts_lst, columns=[\n",
    "        'shortcode',\n",
    "        'post_type',\n",
    "        'username',\n",
    "        'like',\n",
    "        'comment',\n",
    "        'object_1',\n",
    "        'object_2',\n",
    "        'object_3',\n",
    "        'object_4',\n",
    "        'object_5',\n",
    "        'object_6'\n",
    "    ])\n",
    "\n",
    "    if temp_df.username.isin(main_posts_df.username)[0]:\n",
    "        print('User post information already exist, skiping...')\n",
    "        continue\n",
    "    else:\n",
    "        print(f'Adding {username} posts information...')\n",
    "        main_posts_df = pd.concat([main_posts_df, temp_df], axis=0, join='outer')\n",
    "    \n",
    "    # saving the data each time\n",
    "    main_accounts_df.to_csv('Data/accounts.csv')\n",
    "    main_posts_df.to_csv('Data/posts.csv')\n",
    "\n",
    "    # waiting 5 sec for each  user, instagram rate limit\n",
    "    print('Waiting 5 seconds...')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = {\n",
    "            \"csrf_token\": csrf_token,\n",
    "            \"session_id\": session_id\n",
    "        }\n",
    "\n",
    "headers = {\n",
    "            \"x-csrftoken\": session['csrf_token'],\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36',\n",
    "            \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "            \"Referer\": \"https://www.instagram.com/accounts/login/\",\n",
    "            'Accept': '*/*',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'X-Instagram-AJAX': 'c6412f1b1b7b',\n",
    "            'X-IG-App-ID': '936619743392459',\n",
    "            'X-ASBD-ID': '198387',\n",
    "            'X-IG-WWW-Claim': '0',\n",
    "            'X-Requested-With': 'XMLHttpRequest',\n",
    "            'Origin': 'https://www.instagram.com',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Referer': 'https://www.instagram.com/accounts/login/?',\n",
    "            'Sec-Fetch-Dest': 'empty',\n",
    "            'Sec-Fetch-Mode': 'cors',\n",
    "            'Sec-Fetch-Site': 'same-origin',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'Sec-Fetch-Dest': 'document',\n",
    "            'Sec-Fetch-Mode': 'navigate',\n",
    "            'Sec-Fetch-Site': 'none',\n",
    "            'Sec-Fetch-User': '?1',\n",
    "            'TE': 'trailers'\n",
    "        }\n",
    "\n",
    "cookies = {\n",
    "            \"sessionid\": session['session_id'],\n",
    "            \"csrftoken\": session['csrf_token']\n",
    "        }\n",
    "url = f'https://www.instagram.com/arianagrande/?__a=1&__d=dis'\n",
    "res = requests.get(url, headers=headers, cookies=cookies)\n",
    "# add error handling here based on response codes, reference -> InstagramBot.py\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section need to be changed to sent requests and process the json which is in the response\n",
    "f = open('Data/account_response.json', 'r')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = data['graphql']['user']['edge_followed_by']['count']\n",
    "following = data['graphql']['user']['edge_follow']['count']\n",
    "ar_effect = data['graphql']['user']['has_ar_effects']\n",
    "id = data['graphql']['user']['id']\n",
    "type_business = data['graphql']['user']['is_business_account']\n",
    "type_professional = data['graphql']['user']['is_professional_account']\n",
    "category = data['graphql']['user']['category_name']\n",
    "verified = data['graphql']['user']['is_verified']\n",
    "reel_count = data['graphql']['user']['edge_felix_video_timeline']['count']\n",
    "media_count = data['graphql']['user']['edge_owner_to_timeline_media']['count']\n",
    "username = data['graphql']['user']['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reel_view_list = []\n",
    "reel_like_list = []\n",
    "reel_comment_list = []\n",
    "reel_duration_list = []\n",
    "reel_timestamp_list = []\n",
    "\n",
    "media_like_list = []\n",
    "media_comment_list = []\n",
    "media_timestamp_list = []\n",
    "\n",
    "for video in data['graphql']['user']['edge_felix_video_timeline']['edges']:\n",
    "    reel_view_list.append(video['node']['video_view_count'])\n",
    "    reel_comment_list.append(video['node']['edge_media_to_comment']['count'])\n",
    "    reel_timestamp_list.append(video['node']['taken_at_timestamp'])\n",
    "    reel_like_list.append(video['node']['edge_liked_by']['count'])\n",
    "    reel_duration_list.append(video['node']['video_duration'])\n",
    "\n",
    "for medium in data['graphql']['user']['edge_owner_to_timeline_media']['edges']:\n",
    "    media_comment_list.append(medium['node']['edge_media_to_comment']['count'])\n",
    "    media_timestamp_list.append(medium['node']['taken_at_timestamp'])\n",
    "    media_like_list.append(medium['node']['edge_liked_by']['count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reel_utc_list = [datetime.utcfromtimestamp(ts) for ts in reel_timestamp_list]\n",
    "media_utc_list = [datetime.utcfromtimestamp(ts) for ts in media_timestamp_list]\n",
    "\n",
    "reel_utc_difference_list = [reel_utc_list[i] - reel_utc_list[i+1] for i in range(len(reel_utc_list) - 1)]\n",
    "media_utc_difference_list = [media_utc_list[i] - media_utc_list[i+1] for i in range(len(media_utc_list) - 1)]\n",
    "\n",
    "if reel_count > 1:\n",
    "    reel_frequency = np.mean(reel_utc_difference_list).days + (np.mean(reel_utc_difference_list).seconds / 86_400) + (np.mean(reel_utc_difference_list).microseconds / 1_000_000 / 84_600)\n",
    "else:\n",
    "    reel_frequency = 0\n",
    "media_frequency = np.mean(media_utc_difference_list).days + (np.mean(media_utc_difference_list).seconds / 86_400) + (np.mean(media_utc_difference_list).microseconds / 1_000_000 / 84_600)\n",
    "\n",
    "reel_view_mean = np.mean(reel_view_list)\n",
    "reel_like_mean = np.mean(reel_like_list)\n",
    "reel_comment_mean = np.mean(reel_comment_list)\n",
    "reel_duration_mean = np.mean(reel_duration_list)\n",
    "\n",
    "media_like_mean = np.mean(media_like_list)\n",
    "media_comment_mean = np.mean(media_comment_list)\n",
    "\n",
    "entry_lst = [id, username, category, followers, following, ar_effect, type_business, type_professional, verified, reel_count, reel_view_mean, reel_comment_mean, reel_like_mean, reel_duration_mean, reel_frequency, media_count, media_comment_mean, media_like_mean, media_frequency]\n",
    "\n",
    "accounts_df = pd.DataFrame([entry_lst] ,columns=['id', 'username', 'category_name', 'follower', 'following', 'ar_effect', 'type_business', 'type_professional', 'verified', 'reel_count', 'reel_avg_view', 'reel_avg_comment', 'reel_avg_like', 'reel_avg_duration', 'reel_frequency', 'media_count', 'media_avg_comment', 'media_avg_like', 'media_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>category_name</th>\n",
       "      <th>follower</th>\n",
       "      <th>following</th>\n",
       "      <th>ar_effect</th>\n",
       "      <th>type_business</th>\n",
       "      <th>type_professional</th>\n",
       "      <th>verified</th>\n",
       "      <th>reel_count</th>\n",
       "      <th>reel_avg_view</th>\n",
       "      <th>reel_avg_comment</th>\n",
       "      <th>reel_avg_like</th>\n",
       "      <th>reel_avg_duration</th>\n",
       "      <th>reel_frequency</th>\n",
       "      <th>media_count</th>\n",
       "      <th>media_avg_comment</th>\n",
       "      <th>media_avg_like</th>\n",
       "      <th>media_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7719696</td>\n",
       "      <td>arianagrande</td>\n",
       "      <td>Musician</td>\n",
       "      <td>367888326</td>\n",
       "      <td>600</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1309</td>\n",
       "      <td>9.167998e+06</td>\n",
       "      <td>40.5</td>\n",
       "      <td>2158336.25</td>\n",
       "      <td>49.31075</td>\n",
       "      <td>18.352435</td>\n",
       "      <td>4987</td>\n",
       "      <td>2367.666667</td>\n",
       "      <td>3577108.0</td>\n",
       "      <td>13.360044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      username category_name   follower  following  ar_effect  \\\n",
       "0  7719696  arianagrande      Musician  367888326        600      False   \n",
       "\n",
       "   type_business  type_professional  verified  reel_count  reel_avg_view  \\\n",
       "0          False               True      True        1309   9.167998e+06   \n",
       "\n",
       "   reel_avg_comment  reel_avg_like  reel_avg_duration  reel_frequency  \\\n",
       "0              40.5     2158336.25           49.31075       18.352435   \n",
       "\n",
       "   media_count  media_avg_comment  media_avg_like  media_frequency  \n",
       "0         4987        2367.666667       3577108.0        13.360044  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    \"\"\"A helper function to flatten any dimensional python list to 1D one.\n",
    "\n",
    "    Args:\n",
    "        lst (list): multi dimension python list\n",
    "\n",
    "    Returns:\n",
    "        list: flattened list\n",
    "    \"\"\"\n",
    "    rt = []\n",
    "    for i in lst:\n",
    "        if isinstance(i,list): rt.extend(flatten(i))\n",
    "        else: rt.append(i)\n",
    "    return rt\n",
    "\n",
    "# main lists structure is:\n",
    "#   shortcode, post_type, username, objects\n",
    "posts_lst = []\n",
    "for post in data['graphql']['user']['edge_owner_to_timeline_media']['edges']:\n",
    "    temp_lst = []\n",
    "    objects = []\n",
    "    temp_lst.append(post['node']['shortcode'])\n",
    "    temp_lst.append(post['node']['__typename'])\n",
    "    temp_lst.append(data['graphql']['user']['username'])\n",
    "    temp_lst.append(post['node']['edge_liked_by']['count'])\n",
    "    temp_lst.append(post['node']['edge_media_to_comment']['count'])\n",
    "    if post['node']['__typename'] == 'GraphImage' or post['node']['__typename'] == 'GraphSidecar':\n",
    "        # split object-detection output\n",
    "        if post['node']['accessibility_caption'] == None:\n",
    "            objects = []\n",
    "            continue\n",
    "        objects = post['node']['accessibility_caption'].split('.')[1]\n",
    "        # terminating empty lists\n",
    "        if objects:\n",
    "            try:\n",
    "            # cutting objects\n",
    "                objects = objects.split('of')[1]\n",
    "                objects = objects.split('and', 1)\n",
    "                objects[0] = objects[0].split(',')\n",
    "                if 'text' in objects[1]:\n",
    "                    objects[1] = 'text'\n",
    "            except:\n",
    "                continue\n",
    "            # flattening the objects list to make the dimension 1D\n",
    "            objects = flatten(objects)\n",
    "            # terminating leading and trailing spaces from list items\n",
    "            objects = [item.strip() for item in objects]\n",
    "        else:\n",
    "            objects = []\n",
    "    # padding the objects list, we set the limit to 6 objects\n",
    "    objects += ['No Object'] * (6 - len(objects))\n",
    "    if len(objects) > 6:\n",
    "        objects = objects[:6]\n",
    "    temp_lst.append(objects)\n",
    "    posts_lst.append(flatten(temp_lst))\n",
    "\n",
    "# creating temporary dataframe for posts of this account\n",
    "temp_df = pd.DataFrame(posts_lst, columns=[\n",
    "    'shortcode',\n",
    "    'post_type',\n",
    "    'username',\n",
    "    'like',\n",
    "    'comment',\n",
    "    'object_1',\n",
    "    'object_2',\n",
    "    'object_3',\n",
    "    'object_4',\n",
    "    'object_5',\n",
    "    'object_6'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shortcode</th>\n",
       "      <th>post_type</th>\n",
       "      <th>username</th>\n",
       "      <th>like</th>\n",
       "      <th>comment</th>\n",
       "      <th>object_1</th>\n",
       "      <th>object_2</th>\n",
       "      <th>object_3</th>\n",
       "      <th>object_4</th>\n",
       "      <th>object_5</th>\n",
       "      <th>object_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CqLUeUppDYs</td>\n",
       "      <td>GraphSidecar</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>3180843</td>\n",
       "      <td>25102</td>\n",
       "      <td>2 people</td>\n",
       "      <td>makeup</td>\n",
       "      <td>people kissing</td>\n",
       "      <td>suit</td>\n",
       "      <td>overcoat</td>\n",
       "      <td>dinner jacket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CqLUQ_upwT0</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>1539359</td>\n",
       "      <td>18315</td>\n",
       "      <td>1 person</td>\n",
       "      <td>magazine</td>\n",
       "      <td>text</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cp3vzkhp1Ug</td>\n",
       "      <td>GraphSidecar</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>4515558</td>\n",
       "      <td>52969</td>\n",
       "      <td>1 person</td>\n",
       "      <td>makeup</td>\n",
       "      <td>dress</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoZ98CJDHRZ</td>\n",
       "      <td>GraphVideo</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>4753985</td>\n",
       "      <td>88044</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoZJBmpuIlD</td>\n",
       "      <td>GraphSidecar</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>3586900</td>\n",
       "      <td>27435</td>\n",
       "      <td>miniskirt</td>\n",
       "      <td>drawstring</td>\n",
       "      <td>top</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoTojVarwg_</td>\n",
       "      <td>GraphSidecar</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>2860019</td>\n",
       "      <td>31583</td>\n",
       "      <td>one or more people</td>\n",
       "      <td>makeup</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CoRHCpauzUG</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>2144468</td>\n",
       "      <td>22590</td>\n",
       "      <td>one or more people</td>\n",
       "      <td>makeup</td>\n",
       "      <td>dress</td>\n",
       "      <td>miniskirt</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CoHxOQhrTHX</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>8670783</td>\n",
       "      <td>225761</td>\n",
       "      <td>costume</td>\n",
       "      <td>tinfoil</td>\n",
       "      <td>fishnet stockings</td>\n",
       "      <td>headdress</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CkhUy2bL0_9</td>\n",
       "      <td>GraphImage</td>\n",
       "      <td>beyonce</td>\n",
       "      <td>5640978</td>\n",
       "      <td>76182</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "      <td>No Object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     shortcode     post_type username     like  comment            object_1  \\\n",
       "0  CqLUeUppDYs  GraphSidecar  beyonce  3180843    25102            2 people   \n",
       "1  CqLUQ_upwT0    GraphImage  beyonce  1539359    18315            1 person   \n",
       "2  Cp3vzkhp1Ug  GraphSidecar  beyonce  4515558    52969            1 person   \n",
       "3  CoZ98CJDHRZ    GraphVideo  beyonce  4753985    88044           No Object   \n",
       "4  CoZJBmpuIlD  GraphSidecar  beyonce  3586900    27435           miniskirt   \n",
       "5  CoTojVarwg_  GraphSidecar  beyonce  2860019    31583  one or more people   \n",
       "6  CoRHCpauzUG    GraphImage  beyonce  2144468    22590  one or more people   \n",
       "7  CoHxOQhrTHX    GraphImage  beyonce  8670783   225761             costume   \n",
       "8  CkhUy2bL0_9    GraphImage  beyonce  5640978    76182           No Object   \n",
       "\n",
       "     object_2           object_3   object_4   object_5       object_6  \n",
       "0      makeup     people kissing       suit   overcoat  dinner jacket  \n",
       "1    magazine               text  No Object  No Object      No Object  \n",
       "2      makeup              dress  No Object  No Object      No Object  \n",
       "3   No Object          No Object  No Object  No Object      No Object  \n",
       "4  drawstring                top  No Object  No Object      No Object  \n",
       "5      makeup          No Object  No Object  No Object      No Object  \n",
       "6      makeup              dress  miniskirt  No Object      No Object  \n",
       "7     tinfoil  fishnet stockings  headdress  No Object      No Object  \n",
       "8   No Object          No Object  No Object  No Object      No Object  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
